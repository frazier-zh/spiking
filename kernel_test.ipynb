{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "2.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist_data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./mnist_data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./mnist_data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 25\n",
    "classes = 10\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, neurons, 5)\n",
    "        for param in self.conv1.parameters():\n",
    "            param.requires_grad = False # freeze the kernel weights\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(neurons*12*12, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters())\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def train():\n",
    "    print(\"start training [\", end=\"\")\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        for inputs, labels in trainloader:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('*', end='')\n",
    "    print(\"] finished.\")\n",
    "\n",
    "def test():\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for input, label in testloader:\n",
    "            input = input.to(device)\n",
    "            label = label.to(device)\n",
    "            output = net(input)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(label.data.view_as(pred)).sum()\n",
    "    \n",
    "    print('{:.6f}'.format(correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training [**********] finished.\n",
      "0.970100\n"
     ]
    }
   ],
   "source": [
    "# First pass training\n",
    "net.apply(init_weights)\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "\n",
    "work_path = './snapshots_02292024_1014/'\n",
    "\n",
    "# Load the synapses from the trained network\n",
    "fe_net = pickle.load(open(work_path+'net_6000.pkl', 'rb'))\n",
    "synapse = fe_net.synapses\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.conv1.weight.data = torch.from_numpy(synapse.astype(np.float32).reshape(neurons, 1, 5, 5)).to(device)\n",
    "    net.conv1.bias.data.fill_(0)\n",
    "\n",
    "train()\n",
    "test()\n",
    "\n",
    "torch.save(net.state_dict(), work_path+'ann_6000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.644200\n",
      "0.759400\n",
      "0.817700\n",
      "0.790500\n",
      "0.825700\n",
      "0.907100\n",
      "0.945600\n",
      "0.957600\n",
      "0.960300\n",
      "0.964900\n",
      "0.966700\n",
      "0.966300\n",
      "0.964700\n",
      "0.966300\n",
      "0.966400\n",
      "0.967900\n",
      "0.967800\n",
      "0.967700\n",
      "0.969100\n",
      "0.968400\n",
      "0.968000\n",
      "0.968200\n",
      "0.968500\n",
      "0.969100\n",
      "0.968800\n",
      "0.968800\n",
      "0.968900\n",
      "0.968600\n",
      "0.968600\n",
      "0.968500\n",
      "0.968900\n",
      "0.968800\n",
      "0.968600\n",
      "0.968700\n",
      "0.968800\n",
      "0.969100\n",
      "0.969000\n",
      "0.969400\n",
      "0.969300\n",
      "0.969600\n",
      "0.969100\n",
      "0.969200\n",
      "0.969600\n",
      "0.969600\n",
      "0.969400\n",
      "0.968700\n",
      "0.969700\n",
      "0.969400\n",
      "0.969600\n",
      "0.969500\n",
      "0.970400\n",
      "0.969900\n",
      "0.969600\n",
      "0.970100\n",
      "0.969700\n",
      "0.969600\n",
      "0.969800\n",
      "0.969900\n",
      "0.969500\n",
      "0.970100\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(work_path+'ann_6000'))\n",
    "\n",
    "for i in range(60):\n",
    "    fe_net = pickle.load(open(work_path+f'net_{i+1}00.pkl', 'rb'))\n",
    "    synapse = fe_net.synapses\n",
    "    with torch.no_grad():\n",
    "        net.conv1.weight.data = torch.from_numpy(synapse.astype(np.float32).reshape(neurons, 1, 5, 5)).to(device)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(array, fname, w_min=0, w_max=1, size=None, arange=None):\n",
    "    num = array.shape[0]\n",
    "\n",
    "    if arange is None:\n",
    "        cols = int(np.ceil(np.sqrt(num)))\n",
    "        rows = int((num-1)/cols)+1\n",
    "    else:\n",
    "        cols, rows = arange\n",
    "\n",
    "    if size is None:\n",
    "        if len(array.shape) == 2:\n",
    "            pixels = array.shape[1]\n",
    "            y = int(np.ceil(np.sqrt(pixels)))\n",
    "            x = int((pixels-1)/y)+1\n",
    "            size = [x, y]\n",
    "        elif len(array.shape) == 3:\n",
    "            size = array.shape[1:3]\n",
    "\n",
    "    scale = np.max(size)/10\n",
    "\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(scale*cols, scale*rows))\n",
    "    plt.subplots_adjust(bottom=.01, left=.01, right=.99, top=.99)\n",
    "\n",
    "    for i in range(0, num):\n",
    "        data = array[i].reshape(size)\n",
    "\n",
    "        axs = fig.add_subplot(rows, cols, i+1)\n",
    "        axs.set_xticks([])\n",
    "        axs.set_yticks([])\n",
    "\n",
    "        img = axs.imshow(data, vmin=w_min, vmax=w_max, cmap='gray')\n",
    "    # colorbar\n",
    "    #fig.colorbar(img, cax=fig.add_axes([0.2, 0.93, 0.6, 0.03]), orientation='horizontal')\n",
    "\n",
    "    plt.savefig(fname+'.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(synapse, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
